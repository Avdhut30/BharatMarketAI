# app.py
# Professional + accuracy-focused dashboard + Monthly Heatmap + Symbol Contribution
# + Advisor + News features shown inside Advisor (if news_daily.csv exists)
# + Mutual Funds (MF Central-style dashboard)

import os
import re
import glob
import json
import pandas as pd
import streamlit as st

from src.backtest.strategy import StrategyConfig
from src.backtest.metrics import summary_stats

# Must exist in your project
from src.backtest.oos_backtest_topk_nolookahead import load_oos, backtest_topk_nolookahead
from src.ui.advisor import score_single_symbol

# Mutual Funds Dashboard
from src.mf.ui.mf_pages import mf_dashboard

REPORTS_DIR = "reports"
DATA_DIR = "data_cache"
SELECTED_CONFIG_PATH = os.path.join(REPORTS_DIR, "selected_config.json")


# ----------------------------
# Utils
# ----------------------------
def latest_file(pattern: str):
    files = glob.glob(pattern)
    return max(files, key=os.path.getmtime) if files else None


@st.cache_data(show_spinner=False)
def read_csv(path: str):
    return pd.read_csv(path)


@st.cache_data(show_spinner=False)
def read_equity(path: str):
    df = pd.read_csv(path)
    df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
    df = df.dropna(subset=["Date"]).set_index("Date").sort_index()
    return df


def exists(p):
    return p is not None and os.path.exists(p)


def fmt_pct(x):
    return f"{x * 100:.2f}%"


def fmt_num(x):
    return f"{x:.4f}"


def kpi_card(label: str, value: str, help_text: str = ""):
    st.markdown(
        f"""
        <div style="
            padding: 14px 14px;
            border-radius: 18px;
            background: rgba(255,255,255,0.05);
            border: 1px solid rgba(255,255,255,0.12);
            ">
            <div style="font-size: 12px; opacity: 0.75;">{label}</div>
            <div style="font-size: 22px; font-weight: 700; margin-top: 4px;">{value}</div>
            <div style="font-size: 12px; opacity: 0.70; margin-top: 6px;">{help_text}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )


def df_date_vertical(df: pd.DataFrame, date_col_name="Date") -> pd.DataFrame:
    """
    Ensures Date is shown as a vertical column (not as index).
    If df has DatetimeIndex -> reset to Date column.
    """
    out = df.copy()
    if isinstance(out.index, pd.DatetimeIndex):
        out = out.reset_index().rename(columns={"index": date_col_name})
    if date_col_name in out.columns:
        out[date_col_name] = pd.to_datetime(out[date_col_name], errors="coerce")
        out = out.dropna(subset=[date_col_name])
    return out


def load_selected_threshold(default=0.52):
    """
    Loads threshold from reports/selected_threshold.txt safely.
    Always clamps into [0.50, 0.95]
    """
    path = os.path.join(REPORTS_DIR, "selected_threshold.txt")
    val = default

    if os.path.exists(path):
        try:
            txt = open(path, "r", encoding="utf-8").read()
            m = re.search(r"threshold\s+([0]\.\d+)", txt, flags=re.IGNORECASE)
            if not m:
                m = re.search(r"\b([0]\.\d+)\b", txt)
            if m:
                val = float(m.group(1))
        except Exception:
            val = default

    val = max(0.50, min(0.95, float(val)))
    return val


def load_selected_config():
    """
    Loads best config from reports/selected_config.json (generated by robustness_grid).
    Returns dict or None.
    """
    if not os.path.exists(SELECTED_CONFIG_PATH):
        return None
    try:
        with open(SELECTED_CONFIG_PATH, "r", encoding="utf-8") as f:
            cfg = json.load(f)
        if "threshold" not in cfg:
            return None
        return cfg
    except Exception:
        return None


def default_lab_params(default_threshold: float):
    """
    Uses selected_config.json if present, otherwise falls back.
    """
    cfg = load_selected_config()
    if cfg is None:
        return {
            "threshold": float(default_threshold),
            "top_k": 3,
            "round_trip_cost": 0.0010,
            "exit_threshold": 0.50,
            "trend_filter": True,
        }

    th = float(cfg.get("threshold", default_threshold))
    th = max(0.50, min(0.95, th))

    topk = int(cfg.get("top_k", 3))
    if topk not in [1, 3, 5]:
        topk = 3

    cost = float(cfg.get("round_trip_cost", 0.0010))
    if cost not in [0.0005, 0.0010, 0.0020]:
        cost = 0.0010

    ex = float(cfg.get("exit_threshold", 0.50))
    ex = max(0.40, min(0.60, ex))

    trend = bool(cfg.get("trend_filter", True))

    return {
        "threshold": th,
        "top_k": topk,
        "round_trip_cost": cost,
        "exit_threshold": ex,
        "trend_filter": trend,
    }


def infer_mean_wf_auc(oos_df: pd.DataFrame):
    cols = set(oos_df.columns)
    if not {"wf_train_start", "wf_train_end", "wf_test_end"}.issubset(cols):
        return None

    target_cols = [c for c in oos_df.columns if c.startswith("target_up_")]
    if not target_cols:
        return None

    ycol = target_cols[0]
    try:
        from sklearn.metrics import roc_auc_score
        aucs = []
        for _, g in oos_df.groupby(["wf_train_start", "wf_train_end", "wf_test_end"]):
            if g[ycol].nunique() < 2:
                continue
            aucs.append(roc_auc_score(g[ycol].astype(int), g["p_up_oos"].astype(float)))
        if aucs:
            return float(sum(aucs) / len(aucs))
    except Exception:
        return None

    return None


def load_trade_log():
    p0 = os.path.join(REPORTS_DIR, "trades_topk_nolookahead.csv")
    p1 = os.path.join(REPORTS_DIR, "trades_oos_nolookahead.csv")
    p2 = os.path.join(REPORTS_DIR, "trades_oos.csv")

    if exists(p0):
        df = read_csv(p0)
        df["_source"] = "trades_topk_nolookahead.csv"
        return df
    if exists(p1):
        df = read_csv(p1)
        df["_source"] = "trades_oos_nolookahead.csv"
        return df
    if exists(p2):
        df = read_csv(p2)
        df["_source"] = "trades_oos.csv"
        return df

    return None


def monthly_returns_table(equity_df: pd.DataFrame) -> pd.DataFrame:
    eq = equity_df.copy().sort_index()
    eq["ret"] = eq["Equity"].pct_change().fillna(0.0)

    monthly = (1.0 + eq["ret"]).resample("ME").prod() - 1.0
    if monthly.empty:
        return pd.DataFrame()

    mdf = monthly.to_frame("mret")
    mdf["Year"] = mdf.index.year
    mdf["Month"] = mdf.index.month

    pivot = mdf.pivot_table(index="Year", columns="Month", values="mret", aggfunc="first").sort_index()
    pivot["YTD"] = pivot.apply(lambda r: (1.0 + r.dropna()).prod() - 1.0, axis=1)

    month_names = {
        1: "Jan", 2: "Feb", 3: "Mar", 4: "Apr", 5: "May", 6: "Jun",
        7: "Jul", 8: "Aug", 9: "Sep", 10: "Oct", 11: "Nov", 12: "Dec"
    }
    pivot = pivot.rename(columns=month_names)

    ordered_cols = ["Jan", "Feb", "Mar", "Apr", "May", "Jun",
                    "Jul", "Aug", "Sep", "Oct", "Nov", "Dec", "YTD"]
    for c in ordered_cols:
        if c not in pivot.columns:
            pivot[c] = None

    return pivot[ordered_cols]


def style_heatmap(df: pd.DataFrame):
    def fmt(x):
        if pd.isna(x):
            return ""
        return f"{x * 100:.2f}%"

    def color(x):
        if pd.isna(x):
            return ""
        if x > 0:
            return "background-color: rgba(46, 204, 113, 0.18);"
        if x < 0:
            return "background-color: rgba(231, 76, 60, 0.18);"
        return "background-color: rgba(255, 255, 255, 0.05);"

    return df.style.format(fmt).map(color)


def pick_news_cols(df: pd.DataFrame):
    candidates = [
        "news_count",
        "sent_compound_mean", "sent_compound_std", "sent_compound_min", "sent_compound_max",
        "geo_risk_sum", "oil_energy_sum", "rates_inflation_sum", "india_sum",
    ]
    return [c for c in candidates if c in df.columns]


# ----------------------------
# Page config + styling (ONLY ONCE)
# ----------------------------
st.set_page_config(page_title="BharatMarketAI", layout="wide")

st.markdown(
    """
    <style>
    .block-container { padding-top: 1.1rem; }
    h1, h2, h3 { letter-spacing: -0.02em; }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("üìä BharatMarketAI")
st.caption("Walk-forward OOS + no-lookahead backtesting dashboard (research-only).")


# ----------------------------
# Sidebar nav
# ----------------------------
st.sidebar.title("Navigation")
page = st.sidebar.radio(
    "Go to",
    ["üè† Overview", "üéØ Signals", "üß™ Backtest Lab", "üß† Advisor", "üì∞ News", "üìÅ Files", "üìà Mutual Funds"],
    index=0,
)

DEFAULT_THRESHOLD = load_selected_threshold(default=0.52)
BEST_CONFIG = load_selected_config()

equity_oos_path = os.path.join(REPORTS_DIR, "equity_curve_oos.csv")
equity_oos_nl_path = os.path.join(REPORTS_DIR, "equity_curve_oos_nolookahead.csv")
equity_oos_topk_nl_path = os.path.join(REPORTS_DIR, "equity_curve_oos_topk_nolookahead.csv")

threshold_grid_nl_path = os.path.join(REPORTS_DIR, "threshold_grid_nolookahead.csv")
robustness_grid_path = os.path.join(REPORTS_DIR, "robustness_grid.csv")

news_daily_path = os.path.join(DATA_DIR, "news_daily.csv")
news_raw_path = os.path.join(DATA_DIR, "news_raw.csv")


# ----------------------------
# Pages
# ----------------------------
if page == "üè† Overview":
    st.subheader("Performance Snapshot (from saved reports)")

    eq_topk_nl = read_equity(equity_oos_topk_nl_path) if exists(equity_oos_topk_nl_path) else None

    c1, c2, c3, c4 = st.columns(4)
    if eq_topk_nl is not None and not eq_topk_nl.empty:
        stats = summary_stats(eq_topk_nl["Equity"])
        with c1:
            kpi_card("CAGR", fmt_pct(stats["CAGR"]), "Top-K no-lookahead")
        with c2:
            kpi_card("Sharpe", fmt_num(stats["Sharpe"]), "Top-K no-lookahead")
        with c3:
            kpi_card("Max Drawdown", fmt_pct(stats["MaxDrawdown"]), "Top-K no-lookahead")
        with c4:
            kpi_card("Total Return", fmt_pct(stats["TotalReturn"]), f"Over {stats['Days']} days")
    else:
        st.info("No `equity_curve_oos_topk_nolookahead.csv` found yet. Generate backtests first.")

    st.divider()

    st.subheader("Equity Curves")
    chart_df = pd.DataFrame()

    if exists(equity_oos_path):
        chart_df["OOS (legacy)"] = read_equity(equity_oos_path)["Equity"]
    if exists(equity_oos_nl_path):
        chart_df["OOS No-lookahead (1-pos)"] = read_equity(equity_oos_nl_path)["Equity"]
    if exists(equity_oos_topk_nl_path):
        chart_df["OOS Top-K No-lookahead"] = read_equity(equity_oos_topk_nl_path)["Equity"]

    if chart_df.empty:
        st.warning("No equity curves found in reports. Generate backtests first.")
    else:
        st.line_chart(chart_df)

        # ‚úÖ Date shown vertically in a table too
        st.caption("Latest equity curve points (Date shown vertically)")
        eq_table = df_date_vertical(chart_df, date_col_name="Date").tail(30)
        st.dataframe(eq_table, width="stretch")

    st.divider()
    st.subheader("Monthly Returns Heatmap (Top-K No-lookahead)")

    if eq_topk_nl is None or eq_topk_nl.empty:
        st.info("Generate `equity_curve_oos_topk_nolookahead.csv` to view monthly heatmap.")
    else:
        heat = monthly_returns_table(eq_topk_nl)
        if heat.empty:
            st.info("Not enough data to build monthly table.")
        else:
            st.dataframe(style_heatmap(heat), width="stretch")

    st.divider()
    st.subheader("Symbol Contribution (requires trade log)")

    trades = load_trade_log()
    if trades is None or trades.empty:
        st.info("No trade log found. Run: `python -m src.backtest.oos_backtest_topk_nolookahead_trades`")
    else:
        st.success(f"Loaded trade log: {trades['_source'].iloc[0]}")

        pnl_col = None
        for c in ["PnL_net", "PnL_gross", "PnL", "pnl", "Return", "ret"]:
            if c in trades.columns:
                pnl_col = c
                break

        if pnl_col is None:
            st.warning("Trade log has no PnL column. Expected: PnL_net / PnL_gross.")
        elif "Symbol" not in trades.columns:
            st.warning("Trade log missing `Symbol` column.")
        else:
            t = trades.copy()
            t[pnl_col] = pd.to_numeric(t[pnl_col], errors="coerce")
            t = t.dropna(subset=[pnl_col])

            contrib = (
                t.groupby("Symbol")[pnl_col]
                .agg(["sum", "mean", "count"])
                .rename(columns={"sum": "TotalPnL", "mean": "AvgPnL", "count": "Trades"})
                .sort_values("TotalPnL", ascending=False)
            )

            colA, colB = st.columns(2)
            with colA:
                st.write("üèÜ Top 15 symbols by Total PnL")
                st.dataframe(contrib.head(15), width="stretch")
            with colB:
                st.write("üí• Bottom 15 symbols by Total PnL")
                st.dataframe(contrib.tail(15).sort_values("TotalPnL"), width="stretch")

            st.write("üìå Top 15 symbols by Avg PnL (min 5 trades)")
            contrib2 = contrib[contrib["Trades"] >= 5].sort_values("AvgPnL", ascending=False)
            st.dataframe(contrib2.head(15), width="stretch")

    st.divider()
    st.subheader("Accuracy & Trust checks (quick)")

    oos_path = os.path.join(REPORTS_DIR, "oos_predictions_5d.csv")
    if exists(oos_path):
        oos = read_csv(oos_path)
        with st.expander("OOS dataset quick info", expanded=True):
            st.write(f"Rows: **{len(oos):,}** | Columns: **{len(oos.columns)}**")
            if "p_up_oos" in oos.columns:
                st.write(f"p_up_oos mean: **{oos['p_up_oos'].mean():.3f}**, std: **{oos['p_up_oos'].std():.3f}**")
            mean_auc = infer_mean_wf_auc(oos)
            if mean_auc is not None:
                st.write(f"Estimated mean WF AUC (computed from file): **{mean_auc:.3f}**")
            else:
                st.write("WF AUC not computed here (missing window fields or sklearn).")

            # ‚úÖ Show date vertically if present
            if "Date" in oos.columns:
                oos_view = oos.copy()
                oos_view["Date"] = pd.to_datetime(oos_view["Date"], errors="coerce")
                oos_view = oos_view.dropna(subset=["Date"]).sort_values("Date")
                st.caption("Latest rows (Date shown vertically)")
                st.dataframe(oos_view.tail(30), width="stretch")
    else:
        st.info("No OOS predictions found. Run: `python -m src.models.walk_forward`")


elif page == "üéØ Signals":
    st.subheader("Latest Model Signals")

    latest_pred = latest_file(os.path.join(REPORTS_DIR, "latest_predictions_*.csv"))
    if not latest_pred:
        st.warning("No `latest_predictions_*.csv` found. Run: `python -m src.models.predict`")
    else:
        df = read_csv(latest_pred)
        st.success(f"Loaded: {os.path.basename(latest_pred)}")

        c1, c2, c3 = st.columns(3)
        if "p_up" in df.columns:
            with c1:
                kpi_card("Min p_up", f"{df['p_up'].min():.3f}", "Lowest probability")
            with c2:
                kpi_card("Max p_up", f"{df['p_up'].max():.3f}", "Highest probability")
            with c3:
                kpi_card("Avg p_up", f"{df['p_up'].mean():.3f}", "Average probability")

        st.divider()

        p_cut = st.slider("Minimum p_up", 0.0, 1.0, float(DEFAULT_THRESHOLD), 0.01)
        sort_by = st.selectbox(
            "Sort by",
            [c for c in ["p_up", "Close", "rsi_14", "trend_200"] if c in df.columns],
            index=0,
        )

        out = df[df["p_up"] >= p_cut].copy() if "p_up" in df.columns else df.copy()
        out = out.sort_values(sort_by, ascending=False)

        st.dataframe(out, width="stretch", height=560)
        st.download_button(
            "‚¨áÔ∏è Download filtered signals",
            data=out.to_csv(index=False).encode("utf-8"),
            file_name="latest_signals_filtered.csv",
            mime="text/csv",
        )


elif page == "üß™ Backtest Lab":
    st.subheader("Backtest Lab ‚Äî OOS Top-K No-Lookahead")

    st.caption(
        "Signal is from day **t**; entries are filled at **next-day open (t+1)**. "
        "This avoids lookahead and matches real execution assumptions."
    )

    best_defaults = default_lab_params(DEFAULT_THRESHOLD)
    if BEST_CONFIG:
        st.success(f"Auto-loaded best config ‚Üí {BEST_CONFIG}")
    else:
        st.info("No selected_config.json found. Run: python -m src.backtest.robustness_grid")

    c1, c2, c3, c4, c5 = st.columns(5)

    with c1:
        threshold = st.slider("Entry threshold", 0.50, 0.70, float(best_defaults["threshold"]), 0.01)

    with c2:
        top_k = st.selectbox("Top-K", [1, 3, 5], index=[1, 3, 5].index(int(best_defaults["top_k"])))

    with c3:
        cost = st.selectbox(
            "Round-trip cost",
            [0.0005, 0.0010, 0.0020],
            index=[0.0005, 0.0010, 0.0020].index(float(best_defaults["round_trip_cost"])),
        )

    with c4:
        exit_th = st.slider("Exit threshold", 0.45, 0.55, float(best_defaults["exit_threshold"]), 0.01)

    with c5:
        trend_filter = st.checkbox("Trend_200 filter", value=bool(best_defaults["trend_filter"]))

    colX, colY = st.columns([1, 2])
    with colX:
        run_best = st.button("üèÜ Run Best Config")
    with colY:
        run = st.button("‚ñ∂Ô∏è Run Backtest")

    if exists(threshold_grid_nl_path):
        with st.expander("Threshold grid (No-lookahead) ‚Äî top by Sharpe", expanded=False):
            grid = read_csv(threshold_grid_nl_path)
            st.dataframe(grid.sort_values("Sharpe", ascending=False).head(15), width="stretch")

    if exists(robustness_grid_path):
        with st.expander("Robustness grid ‚Äî top configs", expanded=False):
            rb = read_csv(robustness_grid_path)
            st.dataframe(rb.head(20), width="stretch")

    st.divider()

    if run or run_best:
        if run_best and BEST_CONFIG:
            threshold = float(BEST_CONFIG["threshold"])
            top_k = int(BEST_CONFIG["top_k"])
            cost = float(BEST_CONFIG["round_trip_cost"])
            exit_th = float(BEST_CONFIG["exit_threshold"])
            trend_filter = bool(BEST_CONFIG["trend_filter"])

        with st.spinner("Loading OOS predictions and running backtest..."):
            oos = load_oos()

            cfg = StrategyConfig(
                horizon_days=5,
                p_up_entry=float(threshold),
                p_up_exit=float(exit_th),
                use_trend_200=bool(trend_filter),
                atr_stop_mult=1.5,
                round_trip_cost=float(cost),
            )

            equity_df, stats = backtest_topk_nolookahead(oos, cfg, top_k=int(top_k))

        s = {k: (round(v, 4) if isinstance(v, float) else v) for k, v in stats.items()}

        k1, k2, k3, k4 = st.columns(4)
        with k1:
            kpi_card("CAGR", fmt_pct(s["CAGR"]), "Annualized")
        with k2:
            kpi_card("Sharpe", fmt_num(s["Sharpe"]), "Risk adjusted")
        with k3:
            kpi_card("Max DD", fmt_pct(s["MaxDrawdown"]), "Drawdown")
        with k4:
            kpi_card("Total Return", fmt_pct(s["TotalReturn"]), f"{s['Days']} days")

        st.divider()
        st.line_chart(equity_df["Equity"])

        # ‚úÖ Date shown vertically in table
        st.caption("Latest equity curve points (Date shown vertically)")
        st.dataframe(df_date_vertical(equity_df).tail(30), width="stretch")

        st.download_button(
            "‚¨áÔ∏è Download equity curve",
            data=df_date_vertical(equity_df).to_csv(index=False).encode("utf-8"),
            file_name="equity_curve_backtest_lab.csv",
            mime="text/csv",
        )
    else:
        st.info("Set parameters and click **Run Backtest** or **Run Best Config**.")


elif page == "üß† Advisor":
    st.subheader("üß† Single Stock / Fund Advisor (Buy / Hold / Sell)")
    st.caption("Research-only. Uses your trained model probability + rules. Shows NEWS features used by the model.")

    colA, colB, colC = st.columns([2, 1, 1])
    with colA:
        symbol = st.text_input("Enter Yahoo Finance ticker", value="RELIANCE.NS")
    with colB:
        buy_th = st.number_input("Buy threshold", min_value=0.50, max_value=0.95, value=float(DEFAULT_THRESHOLD), step=0.01)
    with colC:
        sell_th = st.number_input("Sell threshold", min_value=0.05, max_value=0.50, value=0.45, step=0.01)

    require_trend = st.checkbox("Require Trend_200 for BUY", value=True)
    run_one = st.button("üîç Analyze")

    if run_one:
        try:
            with st.spinner("Fetching data + scoring..."):
                feat, latest, p_up, decision = score_single_symbol(
                    symbol=symbol.strip(),
                    buy_threshold=float(buy_th),
                    sell_threshold=float(sell_th),
                    require_trend200_for_buy=bool(require_trend),
                )

            k1, k2, k3, k4 = st.columns(4)
            with k1:
                kpi_card("Decision", decision, "Rule-based using model probability")
            with k2:
                kpi_card("p_up", f"{p_up:.3f}", "Probability of positive return (model)")
            with k3:
                kpi_card("RSI(14)", f"{float(latest.get('rsi_14', float('nan'))):.2f}", "Momentum")
            with k4:
                kpi_card("Trend_200", str(int(latest.get("trend_200", 0))), "1=above SMA200")

            st.divider()

            last_1m = feat.tail(22).copy()
            st.subheader("üìà Last 1 Month Condition")
            st.line_chart(last_1m[["Close"]])

            tech_cols = [c for c in ["Close", "sma_20", "sma_50", "sma_200", "rsi_14", "atr_pct", "vol_z_20"] if c in last_1m.columns]
            st.write("Technical indicators (last 1 month) ‚Äî Date shown vertically")
            st.dataframe(df_date_vertical(last_1m[tech_cols].tail(22)), width="stretch")

            st.divider()

            st.subheader("üì∞ News Features (used by model)")
            news_cols = pick_news_cols(feat)

            if not news_cols:
                st.info("No news features found. Ensure `data_cache/news_daily.csv` exists and advisor merge is enabled.")
            else:
                st.write("Latest day news signals")
                latest_news = pd.DataFrame([latest[news_cols]]).copy()
                latest_news.index = ["Latest Day"]
                st.dataframe(latest_news.T.rename(columns={"Latest Day": "Value"}), width="stretch")

                st.write("Recent news context (last 30 rows) ‚Äî Date shown vertically")
                st.dataframe(df_date_vertical(feat[news_cols].tail(30)), width="stretch")

        except Exception as e:
            st.error(f"Failed to analyze {symbol}: {e}")


elif page == "üì∞ News":
    st.subheader("News Intelligence")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.write("Daily aggregated features (`news_daily.csv`)")
        if exists(news_daily_path):
            daily = read_csv(news_daily_path)
            daily["Date"] = pd.to_datetime(daily["Date"], errors="coerce")
            daily = daily.dropna(subset=["Date"]).sort_values("Date")

            chart_cols = [c for c in ["news_count", "sent_compound_mean", "geo_risk_sum", "oil_energy_sum", "rates_inflation_sum", "india_sum"] if c in daily.columns]
            if chart_cols:
                st.line_chart(daily.set_index("Date")[chart_cols])

            # ‚úÖ date vertical
            st.dataframe(daily.tail(60), width="stretch", height=460)
        else:
            st.warning("Missing `news_daily.csv`. Run:\n`python -m src.data.news`\n`python -m src.features.news_features`")

    with col2:
        st.write("Recent headlines (`news_raw.csv`)")
        if exists(news_raw_path):
            raw = read_csv(news_raw_path)
            if "DateTime" in raw.columns:
                raw["DateTime"] = pd.to_datetime(raw["DateTime"], errors="coerce")
                raw = raw.dropna(subset=["DateTime"]).sort_values("DateTime")
            st.dataframe(raw.tail(80), width="stretch", height=640)
        else:
            st.info("Missing `news_raw.csv`. Run: `python -m src.data.news`")


elif page == "üìÅ Files":
    st.subheader("Files / Health Check")

    st.write("Reports folder:")
    reports_files = sorted(glob.glob(os.path.join(REPORTS_DIR, "*")))
    if reports_files:
        st.dataframe(pd.DataFrame({"reports": [os.path.basename(p) for p in reports_files]}), width="stretch")
    else:
        st.info("No files in `reports/` yet.")

    st.divider()

    st.write("Data cache folder:")
    data_files = sorted(glob.glob(os.path.join(DATA_DIR, "*")))
    if data_files:
        st.dataframe(pd.DataFrame({"data_cache": [os.path.basename(p) for p in data_files]}), width="stretch")
    else:
        st.info("No files in `data_cache/` yet.")

    st.divider()
    st.write("Run checklist:")
    st.code(
        "\n".join(
            [
                "python -m src.data.market",
                "python -m src.data.news",
                "python -m src.features.news_features",
                "python -m src.features.build_features",
                "python -m src.models.walk_forward",
                "python -m src.backtest.robustness_grid",
                "python -m src.backtest.oos_backtest_topk_nolookahead_trades",
                "streamlit run app.py",
            ]
        ),
        language="bash",
    )


elif page == "üìà Mutual Funds":
    mf_dashboard()
